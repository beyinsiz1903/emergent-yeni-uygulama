"""
Celery Tasks for Background Processing
All long-running and periodic tasks
"""

from celery_app import celery_app
from motor.motor_asyncio import AsyncIOMotorClient
import os
from datetime import datetime, timedelta, timezone
import asyncio
import logging
from typing import List, Dict, Any

logger = logging.getLogger(__name__)

# MongoDB connection for tasks
def get_db():
    """Get database connection"""
    mongo_url = os.environ.get('MONGO_URL')
    db_name = os.environ.get('DB_NAME')
    client = AsyncIOMotorClient(mongo_url)
    return client[db_name], client


# ============= NIGHT AUDIT TASKS =============

@celery_app.task(name='celery_tasks.night_audit_task')
def night_audit_task():
    """Run night audit for all tenants"""
    return asyncio.run(_night_audit_async())

async def _night_audit_async():
    """Async night audit implementation"""
    db, client = get_db()
    
    try:
        # Get all active tenants
        tenants = await db.users.distinct('tenant_id', {'active': True})
        
        results = []
        for tenant_id in tenants:
            try:
                # Post room charges for all checked-in bookings
                bookings = await db.bookings.find({
                    'tenant_id': tenant_id,
                    'status': 'checked_in'
                }).to_list(1000)
                
                charges_posted = 0
                for booking in bookings:
                    # Get room rate
                    room_rate = booking.get('total_amount', 0) / max(1, booking.get('nights', 1))
                    
                    # Find guest folio
                    folio = await db.folios.find_one({
                        'tenant_id': tenant_id,
                        'booking_id': booking['booking_id'],
                        'folio_type': 'guest',
                        'status': 'open'
                    })
                    
                    if folio:
                        # Post room charge
                        charge = {
                            'charge_id': f"CHG-{datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S')}-{charges_posted}",
                            'tenant_id': tenant_id,
                            'folio_id': folio['folio_id'],
                            'charge_category': 'room',
                            'description': f"Room charge - {booking.get('room_number', 'N/A')}",
                            'amount': room_rate,
                            'quantity': 1,
                            'unit_price': room_rate,
                            'tax_rate': 0.10,
                            'tax_amount': room_rate * 0.10,
                            'total': room_rate * 1.10,
                            'voided': False,
                            'created_at': datetime.now(timezone.utc)
                        }
                        
                        await db.folio_charges.insert_one(charge)
                        charges_posted += 1
                
                results.append({
                    'tenant_id': tenant_id,
                    'bookings_processed': len(bookings),
                    'charges_posted': charges_posted
                })
                
                logger.info(f"Night audit completed for tenant {tenant_id}: {charges_posted} charges posted")
                
            except Exception as e:
                logger.error(f"Night audit error for tenant {tenant_id}: {e}")
                results.append({
                    'tenant_id': tenant_id,
                    'error': str(e)
                })
        
        return {
            'success': True,
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'results': results
        }
        
    except Exception as e:
        logger.error(f"Night audit task failed: {e}")
        return {
            'success': False,
            'error': str(e)
        }
    finally:
        await client.close()


# ============= DATA ARCHIVAL TASKS =============

@celery_app.task(name='celery_tasks.archive_old_data_task')
def archive_old_data_task():
    """Archive data older than 6 months"""
    return asyncio.run(_archive_old_data_async())

async def _archive_old_data_async():
    """Async data archival implementation"""
    db, client = get_db()
    
    try:
        # Archive cutoff date: 6 months ago
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=180)
        
        results = {
            'cutoff_date': cutoff_date.isoformat(),
            'archived': {}
        }
        
        # Archive old bookings (checked_out > 6 months ago)
        old_bookings = await db.bookings.find({
            'status': 'checked_out',
            'check_out': {'$lt': cutoff_date}
        }).to_list(10000)
        
        if old_bookings:
            # Move to archive collection
            await db.bookings_archive.insert_many(old_bookings)
            
            # Delete from main collection
            booking_ids = [b['booking_id'] for b in old_bookings]
            await db.bookings.delete_many({'booking_id': {'$in': booking_ids}})
            
            results['archived']['bookings'] = len(old_bookings)
            logger.info(f"Archived {len(old_bookings)} old bookings")
        
        # Archive old audit logs (> 1 year)
        audit_cutoff = datetime.now(timezone.utc) - timedelta(days=365)
        old_logs = await db.audit_logs.find({
            'timestamp': {'$lt': audit_cutoff}
        }).to_list(50000)
        
        if old_logs:
            await db.audit_logs_archive.insert_many(old_logs)
            log_ids = [log['_id'] for log in old_logs]
            await db.audit_logs.delete_many({'_id': {'$in': log_ids}})
            
            results['archived']['audit_logs'] = len(old_logs)
            logger.info(f"Archived {len(old_logs)} old audit logs")
        
        # Archive old closed folios
        old_folios = await db.folios.find({
            'status': 'closed',
            'closed_at': {'$lt': cutoff_date}
        }).to_list(10000)
        
        if old_folios:
            await db.folios_archive.insert_many(old_folios)
            folio_ids = [f['folio_id'] for f in old_folios]
            await db.folios.delete_many({'folio_id': {'$in': folio_ids}})
            
            results['archived']['folios'] = len(old_folios)
            logger.info(f"Archived {len(old_folios)} old folios")
        
        results['success'] = True
        return results
        
    except Exception as e:
        logger.error(f"Data archival task failed: {e}")
        return {
            'success': False,
            'error': str(e)
        }
    finally:
        await client.close()


# ============= CLEANUP TASKS =============

@celery_app.task(name='celery_tasks.clean_old_notifications_task')
def clean_old_notifications_task():
    """Clean notifications older than 90 days"""
    return asyncio.run(_clean_old_notifications_async())

async def _clean_old_notifications_async():
    """Async notification cleanup"""
    db, client = get_db()
    
    try:
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=90)
        
        result = await db.notifications.delete_many({
            'created_at': {'$lt': cutoff_date}
        })
        
        logger.info(f"Cleaned {result.deleted_count} old notifications")
        
        return {
            'success': True,
            'deleted_count': result.deleted_count,
            'cutoff_date': cutoff_date.isoformat()
        }
        
    except Exception as e:
        logger.error(f"Notification cleanup failed: {e}")
        return {
            'success': False,
            'error': str(e)
        }
    finally:
        await client.close()


# ============= REPORTING TASKS =============

@celery_app.task(name='celery_tasks.generate_daily_reports_task')
def generate_daily_reports_task():
    """Generate daily flash reports for all tenants"""
    return asyncio.run(_generate_daily_reports_async())

async def _generate_daily_reports_async():
    """Async daily report generation"""
    db, client = get_db()
    
    try:
        tenants = await db.users.distinct('tenant_id', {'active': True})
        
        results = []
        for tenant_id in tenants:
            try:
                yesterday = (datetime.now(timezone.utc) - timedelta(days=1)).date()
                
                # Calculate daily metrics
                bookings_yesterday = await db.bookings.count_documents({
                    'tenant_id': tenant_id,
                    'created_at': {
                        '$gte': datetime.combine(yesterday, datetime.min.time()),
                        '$lt': datetime.combine(yesterday + timedelta(days=1), datetime.min.time())
                    }
                })
                
                revenue_yesterday = await db.payments.aggregate([
                    {
                        '$match': {
                            'tenant_id': tenant_id,
                            'created_at': {
                                '$gte': datetime.combine(yesterday, datetime.min.time()),
                                '$lt': datetime.combine(yesterday + timedelta(days=1), datetime.min.time())
                            }
                        }
                    },
                    {
                        '$group': {
                            '_id': None,
                            'total': {'$sum': '$amount'}
                        }
                    }
                ]).to_list(1)
                
                report = {
                    'tenant_id': tenant_id,
                    'report_date': yesterday.isoformat(),
                    'bookings_count': bookings_yesterday,
                    'revenue': revenue_yesterday[0]['total'] if revenue_yesterday else 0,
                    'generated_at': datetime.now(timezone.utc)
                }
                
                await db.daily_reports.insert_one(report)
                results.append(report)
                
            except Exception as e:
                logger.error(f"Daily report generation error for tenant {tenant_id}: {e}")
        
        return {
            'success': True,
            'reports_generated': len(results),
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Daily reports task failed: {e}")
        return {
            'success': False,
            'error': str(e)
        }
    finally:
        await client.close()


# ============= MAINTENANCE TASKS =============

@celery_app.task(name='celery_tasks.check_maintenance_sla_task')
def check_maintenance_sla_task():
    """Check maintenance tasks for SLA violations"""
    return asyncio.run(_check_maintenance_sla_async())

async def _check_maintenance_sla_async():
    """Async SLA check"""
    db, client = get_db()
    
    try:
        # Define SLA thresholds (hours)
        sla_thresholds = {
            'critical': 4,
            'high': 12,
            'medium': 24,
            'low': 72
        }
        
        violations = []
        now = datetime.now(timezone.utc)
        
        for priority, hours in sla_thresholds.items():
            threshold = now - timedelta(hours=hours)
            
            tasks = await db.maintenance_tasks.find({
                'status': {'$in': ['open', 'in_progress']},
                'priority': priority,
                'created_at': {'$lt': threshold}
            }).to_list(1000)
            
            for task in tasks:
                violation = {
                    'task_id': task['task_id'],
                    'room_id': task.get('room_id'),
                    'priority': priority,
                    'created_at': task['created_at'].isoformat(),
                    'hours_open': (now - task['created_at']).total_seconds() / 3600,
                    'sla_hours': hours
                }
                violations.append(violation)
                
                # Create notification for SLA violation
                notification = {
                    'notification_id': f"NOTIF-SLA-{task['task_id']}",
                    'tenant_id': task['tenant_id'],
                    'user_id': task.get('assigned_to', 'maintenance_manager'),
                    'type': 'maintenance_sla_violation',
                    'title': 'SLA Violation',
                    'message': f"Maintenance task {task['task_id']} exceeds {priority} priority SLA ({hours}h)",
                    'priority': 'high',
                    'read': False,
                    'created_at': now
                }
                
                await db.notifications.update_one(
                    {'notification_id': notification['notification_id']},
                    {'$set': notification},
                    upsert=True
                )
        
        logger.info(f"SLA check completed: {len(violations)} violations found")
        
        return {
            'success': True,
            'violations_count': len(violations),
            'violations': violations[:50],  # Return first 50
            'timestamp': now.isoformat()
        }
        
    except Exception as e:
        logger.error(f"SLA check task failed: {e}")
        return {
            'success': False,
            'error': str(e)
        }
    finally:
        await client.close()


# ============= FORECAST TASKS =============

@celery_app.task(name='celery_tasks.update_occupancy_forecast_task')
def update_occupancy_forecast_task():
    """Update occupancy forecast using ML model"""
    return asyncio.run(_update_occupancy_forecast_async())

async def _update_occupancy_forecast_async():
    """Async occupancy forecast update"""
    db, client = get_db()
    
    try:
        # This would integrate with ML model
        # For now, simple calculation
        
        tenants = await db.users.distinct('tenant_id', {'active': True})
        
        results = []
        for tenant_id in tenants:
            # Get next 30 days bookings
            today = datetime.now(timezone.utc).date()
            forecasts = []
            
            for days_ahead in range(30):
                target_date = today + timedelta(days=days_ahead)
                
                # Count confirmed/guaranteed bookings
                bookings_count = await db.bookings.count_documents({
                    'tenant_id': tenant_id,
                    'check_in': {'$lte': target_date},
                    'check_out': {'$gt': target_date},
                    'status': {'$in': ['confirmed', 'guaranteed', 'checked_in']}
                })
                
                # Get total rooms
                total_rooms = await db.rooms.count_documents({'tenant_id': tenant_id})
                
                occupancy_pct = (bookings_count / max(1, total_rooms)) * 100
                
                forecasts.append({
                    'date': target_date.isoformat(),
                    'forecasted_occupancy': round(occupancy_pct, 2),
                    'booked_rooms': bookings_count,
                    'total_rooms': total_rooms
                })
            
            # Store forecast
            await db.occupancy_forecasts.update_one(
                {'tenant_id': tenant_id},
                {
                    '$set': {
                        'tenant_id': tenant_id,
                        'forecasts': forecasts,
                        'updated_at': datetime.now(timezone.utc)
                    }
                },
                upsert=True
            )
            
            results.append({
                'tenant_id': tenant_id,
                'forecasts_generated': len(forecasts)
            })
        
        return {
            'success': True,
            'tenants_updated': len(results),
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Occupancy forecast task failed: {e}")
        return {
            'success': False,
            'error': str(e)
        }
    finally:
        await client.close()


# ============= E-FATURA TASKS =============

@celery_app.task(name='celery_tasks.process_pending_efaturas_task')
def process_pending_efaturas_task():
    """Process pending e-fatura generations"""
    return asyncio.run(_process_pending_efaturas_async())

async def _process_pending_efaturas_async():
    """Async e-fatura processing"""
    db, client = get_db()
    
    try:
        # Find invoices with pending e-fatura
        pending_invoices = await db.accounting_invoices.find({
            'efatura_status': 'pending',
            'invoice_type': 'sales'
        }).limit(100).to_list(100)
        
        processed = 0
        for invoice in pending_invoices:
            try:
                # Generate e-fatura (mock - would call actual API)
                efatura_uuid = f"EFATURA-{invoice['invoice_number']}"
                
                await db.accounting_invoices.update_one(
                    {'invoice_number': invoice['invoice_number']},
                    {
                        '$set': {
                            'efatura_status': 'generated',
                            'efatura_uuid': efatura_uuid,
                            'efatura_generated_at': datetime.now(timezone.utc)
                        }
                    }
                )
                
                processed += 1
                
            except Exception as e:
                logger.error(f"E-fatura generation error for {invoice['invoice_number']}: {e}")
        
        return {
            'success': True,
            'processed': processed,
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"E-fatura processing task failed: {e}")
        return {
            'success': False,
            'error': str(e)
        }
    finally:
        await client.close()


# ============= CACHE WARMING TASKS =============

@celery_app.task(name='celery_tasks.warm_cache_task')
def warm_cache_task():
    """Warm up cache with frequently accessed data"""
    return asyncio.run(_warm_cache_async())

async def _warm_cache_async():
    """Async cache warming"""
    try:
        from cache_manager import warm_dashboard_cache, warm_room_cache
        
        db, client = get_db()
        
        tenants = await db.users.distinct('tenant_id', {'active': True})
        
        for tenant_id in tenants:
            await warm_dashboard_cache(tenant_id, db)
            await warm_room_cache(tenant_id, db)
        
        await client.close()
        
        return {
            'success': True,
            'tenants_warmed': len(tenants),
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Cache warming task failed: {e}")
        return {
            'success': False,
            'error': str(e)
        }


# ============= HEALTH CHECK TASKS =============

@celery_app.task(name='celery_tasks.database_health_check_task')
def database_health_check_task():
    """Check database health and performance"""
    return asyncio.run(_database_health_check_async())

async def _database_health_check_async():
    """Async database health check"""
    db, client = get_db()
    
    try:
        # Test database connection
        await db.command('ping')
        
        # Check collection sizes
        collections_info = {}
        for coll_name in ['bookings', 'rooms', 'guests', 'folios']:
            count = await db[coll_name].count_documents({})
            collections_info[coll_name] = count
        
        # Check for slow queries (would need profiling enabled)
        health_status = {
            'status': 'healthy',
            'collections': collections_info,
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
        
        # Store health check result
        await db.health_checks.insert_one(health_status)
        
        await client.close()
        
        return health_status
        
    except Exception as e:
        logger.error(f"Database health check failed: {e}")
        return {
            'status': 'unhealthy',
            'error': str(e),
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
